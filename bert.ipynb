{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3283ab-36d8-411f-a5ed-21501fe915a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets torch pytorch-lightning transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28cba97-8e2a-4969-b04b-6912f42c0c76",
   "metadata": {},
   "source": [
    "### 0. Сбор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba50c321-720b-4b4d-b136-d9831b6c837f",
   "metadata": {},
   "source": [
    "То, как это собирается сейчас, очень неудобно, я перепишу по-человечески. Мне сами тексты не нужны, но мне нужны последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9246268a-1b86-46ec-8ae2-4c63eaf6a935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from common_utils import correct_aspects, asp_mapper, sent_mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee35884-5c0a-4aba-9327-467563dd9822",
   "metadata": {
    "tags": []
   },
   "source": [
    "Сначала это надо всё считать. Я сделаю точно такой же сплит, но зафиксирую сид, размер теста = 0.25. Проблема в том, что у меня тексты из одного распределения, это не поможет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b15eb2-c809-4540-a5f8-6e21a009dee8",
   "metadata": {},
   "source": [
    "Ещё беда в том, что токены не имеют индекса, я не могу нормально там всё заджойнить. Токены в аспектах и в текстах после эксплоуда не совпадают из-за пунктуации и прочего мусора. Я пофиксил это как смог в `correct_aspects` - если можно разбить целый аспект на несколько маленьких, я так и делаю. Иначе я не смогу их смёрджить и у меня поедет разметка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a7838ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aspects = correct_aspects(pd.read_csv(\n",
    "    \"train_aspects.txt\", delimiter=\"\\t\",\n",
    "    names=[\"text_id\", \"aspect\", \"token\", \"begin\", \"end\", \"sentiment\"]\n",
    "))\n",
    "aspects[\"aspect\"] = aspects.aspect.map(asp_mapper)\n",
    "aspects[\"sentiment\"]= aspects.sentiment.map(sent_mapper)\n",
    "\n",
    "texts = pd.read_csv(\n",
    "    \"train_reviews.txt\", delimiter=\"\\t\",\n",
    "    names=[\"text_id\", \"token\"]\n",
    ")\n",
    "ids = texts.text_id.unique()\n",
    "train_ids, valid_ids = train_test_split(ids, random_state=69, shuffle=True)\n",
    "\n",
    "labels = pd.read_csv(\n",
    "     \"train_cats.txt\", delimiter=\"\\t\",\n",
    "    names=[\"total_asp\", \"total_sent\"]\n",
    ").reset_index(names=[\"text_id\"])\n",
    "labels[\"total_sent\"] = labels.total_sent.map(sent_mapper)\n",
    "labels = labels.groupby(\"text_id\").agg(lambda x: [y for y in x]).reset_index()\n",
    "\n",
    "texts[\"text\"] = texts[\"token\"]\n",
    "texts = texts.sort_values(\"text_id\")\n",
    "texts[\"token\"] = texts[\"token\"].map(lambda x: x.split())\n",
    "texts = texts.explode(\"token\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5660c5e-fbf4-49d0-bc8b-e5f00a11e976",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>aspect</th>\n",
       "      <th>token</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3976</td>\n",
       "      <td>0</td>\n",
       "      <td>ресторане</td>\n",
       "      <td>71</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3976</td>\n",
       "      <td>0</td>\n",
       "      <td>ресторанах</td>\n",
       "      <td>198</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3976</td>\n",
       "      <td>0</td>\n",
       "      <td>ресторане</td>\n",
       "      <td>256</td>\n",
       "      <td>265</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3976</td>\n",
       "      <td>2</td>\n",
       "      <td>Столик</td>\n",
       "      <td>267</td>\n",
       "      <td>273</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3976</td>\n",
       "      <td>2</td>\n",
       "      <td>бронировали</td>\n",
       "      <td>274</td>\n",
       "      <td>285</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id  aspect        token  begin  end  sentiment\n",
       "0     3976       0    ресторане     71   80          3\n",
       "1     3976       0   ресторанах    198  208          3\n",
       "2     3976       0    ресторане    256  265          3\n",
       "3     3976       2       Столик    267  273          3\n",
       "4     3976       2  бронировали    274  285          3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# последние 2 строки - после разбиения одного аспекта, видно по begin-end\n",
    "aspects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5f286-b048-4eaf-a16d-dd93d9311f01",
   "metadata": {},
   "source": [
    "Теперь надо сам индекс добавить и в тексты тоже. Этим вообще должны заниматься те, кто бд делает, но ладно, мне не сложно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53554e61-3891-43de-9171-ed7d1b9e6a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "text_id = 0\n",
    "for idx, row in texts.iterrows():\n",
    "    \n",
    "    if row[\"text_id\"] != text_id:\n",
    "        text_id = row[\"text_id\"]\n",
    "        char_id = 0\n",
    "    texts.loc[idx, \"begin\"] = char_id\n",
    "    token = row[\"token\"]\n",
    "    texts.loc[idx, \"end\"] = char_id + len(token.strip(punctuation))\n",
    "    \n",
    "    char_id += len(token) + 1\n",
    "    \n",
    "texts[[\"begin\", \"end\"]] = texts[[\"begin\", \"end\"]].astype(int)\n",
    "texts[\"token\"] = texts.token.apply(lambda x: x.strip(punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d957851-ecc3-4c13-9fc0-57399dd94e0f",
   "metadata": {},
   "source": [
    "Сами тексты мне тут не нужны, но по памяти это вообще не бьёт - слишком маленькие размеры, я забил. Мёрджим и делаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e75c416-8024-415c-96c9-d4155d633391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    texts.drop(\"text\", axis=1),\n",
    "    aspects,\n",
    "    on=[\"text_id\", \"token\", \"begin\", \"end\"],\n",
    "    how=\"left\"\n",
    ") \\\n",
    "# .rename(columns={\"begin_y\": \"begin\", \"end_y\": \"end\"}) \\\n",
    "# .drop_duplicates([\"begin\", \"end\"]) \\\n",
    "# .sort_values([\"text_id\", \"begin\", \"end\"])\n",
    "        \n",
    "df[\"aspect\"].fillna(5, inplace=True)\n",
    "df[\"sentiment\"].fillna(5, inplace=True)\n",
    "\n",
    "valid = df[df.text_id.isin(valid_ids)]\n",
    "train = df[df.text_id.isin(train_ids)]\n",
    "\n",
    "train_dataset = train.groupby(\"text_id\").agg(lambda x: [y for y in x]).reset_index()\n",
    "valid_dataset = valid.groupby(\"text_id\").agg(lambda x: [y for y in x]).reset_index()\n",
    "train_dataset = pd.merge(train_dataset, labels[[\"text_id\", \"total_sent\"]], on=\"text_id\", how=\"left\")\n",
    "valid_dataset = pd.merge(valid_dataset, labels[[\"text_id\", \"total_sent\"]], on=\"text_id\", how=\"left\")\n",
    "\n",
    "valid_dataset.explode([\"token\", \"begin\", \"end\", \"aspect\", \"sentiment\"]).to_csv(\"valid_meta.csv\", index=0)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset)\n",
    "valid_dataset = Dataset.from_pandas(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ea19a-a45a-4af6-b3e6-71fd1aef35c5",
   "metadata": {},
   "source": [
    "Теперь надо эту красоту токенизировать и сопоставить все аспекты. Было бы удобнее сразу конечно это сделать, а потом бить, чтобы избежать копипасты, но это ради чистоты эксперимента, потому что задачку я чуть-чуть переделал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd5985c-663b-4231-9dac-dad8c997ee86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93a17a3e9b34a82b33c071e1b6e1d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/213 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33a34fe95444b189d522c999d2383d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/71 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bert import tokenize_and_align_labels\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "train_dataset = train_dataset.remove_columns([\"token\", \"begin\", \"end\", \"text_id\", '__index_level_0__'])\n",
    "train_dataset.set_format(\"pt\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "valid_dataset = valid_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "valid_dataset.set_format(\"pt\")\n",
    "\n",
    "meta_cols = [\"begin\", \"end\"]\n",
    "bert_valid_meta = pd.DataFrame(columns=meta_cols)\n",
    "all_tokens = [y for x in valid_dataset[\"token\"] for y in x if y != \"-100\"]\n",
    "bert_valid_meta[\"token\"] = all_tokens\n",
    "for col in meta_cols:\n",
    "    bert_valid_meta[col] = valid_dataset[col][valid_dataset[col] != -100].detach().numpy()\n",
    "    \n",
    "cur_idx = -1\n",
    "for idx, row in bert_valid_meta.iterrows():\n",
    "    if row[\"begin\"] == 0:\n",
    "        cur_idx += 1\n",
    "    bert_valid_meta.loc[idx, \"text_id\"] = valid.text_id.unique()[cur_idx]\n",
    "    \n",
    "bert_valid_meta[\"text_id\"] = bert_valid_meta[\"text_id\"].astype(int)\n",
    "bert_valid_meta = bert_valid_meta[[\"text_id\", \"token\", \"begin\", \"end\"]]\n",
    "bert_valid_meta.to_csv(\"bert_valid_meta.xsv\", index=0)\n",
    "\n",
    "valid_dataset = valid_dataset.remove_columns([\"token\", \"begin\", \"end\", \"text_id\", '__index_level_0__'])\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d34341-497c-4d08-ab11-f946e28aed7b",
   "metadata": {},
   "source": [
    "### 1. Baseline\n",
    "\n",
    "Но сначала надо вернуться на шаг назад и проделать всё, что было в бейзлайне ещё разок, чтоб было с чем сравнивать. Заодно проверим, что моя задачка не совпадает с тем, что делается в бейзлайне, но это и так понятно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9348bd7c-293f-49d7-bd80-2cdcfdbc3045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from baseline import normalize, get_mention_category, label_texts\n",
    "\n",
    "valid_aspects = aspects[aspects.text_id.isin(valid_ids)]\n",
    "train_aspects = aspects[~aspects.text_id.isin(valid_ids)]\n",
    "\n",
    "valid_texts = texts[texts.text_id.isin(valid_ids)]\n",
    "train_texts = texts[~texts.text_id.isin(valid_ids)]\n",
    "\n",
    "train_aspects[\"norm_mention\"] = train_aspects.token.apply(lambda x: tuple(normalize(x)))\n",
    "\n",
    "best_mention_cat = get_mention_category(train_aspects, 'aspect')\n",
    "best_mention_sentiment = get_mention_category(train_aspects, 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62605ebe-2999-4c45-8929-2164c63d7bb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Дальше я это записываю точь в точь, как сделано в тетрадке с бейзлайном, а затем считываю обратно в формате датафрейма. Дальше останется посчитать аккураси"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ade3379f-dcfa-46e8-bcb6-97048e2ce5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "with open('valid_base_aspects.txt', 'w') as f:\n",
    "    for text, idx in valid_texts[['text', 'text_id']].drop_duplicates().values:\n",
    "        for asp in label_texts(text, best_mention_cat, best_mention_sentiment):\n",
    "            print(idx, *asp, sep=\"\\t\", file=f)\n",
    "            \n",
    "# он есть в ноутбуке с бейзлайном, чтобы было максимально честно\n",
    "# with open('valid_aspects.txt', 'w') as f:\n",
    "#     for idx, l in valid_aspects.iterrows():\n",
    "#         print(*l.values, sep=\"\\t\", file=f)\n",
    "            \n",
    "labels = correct_aspects(pd.read_csv(\n",
    "    \"valid_base_aspects.txt\", delimiter=\"\\t\",\n",
    "    names=[\"text_id\", \"aspect\", \"token\", \"begin\", \"end\", \"sentiment\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a9cf2-dfd6-48dd-bdb0-5d9543160007",
   "metadata": {},
   "source": [
    "У меня есть настоящие аспекты и точно такие же предсказанные аспекты. Можно их склеить элементарно, на всякий случай опять удостоверимся, что все токены совпадают через мёрдж"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64c03071-5daa-4d92-95ea-aa0c8d0ce85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "true_pred = reduce(\n",
    "    lambda x, y: pd.merge(x, y, on=[\"text_id\", \"token\", \"begin\", \"end\"], how=\"left\"),\n",
    "    [valid_texts, labels, valid_aspects]\n",
    ").drop([\"text\"], axis=1)\n",
    "\n",
    "# aspect5 и sentiment4 := None\n",
    "true_pred[\"aspect_x\"].fillna(5, inplace=True)\n",
    "true_pred[\"aspect_y\"].fillna(5, inplace=True)\n",
    "\n",
    "true_pred[\"sentiment_x\"].fillna(4, inplace=True)\n",
    "true_pred[\"sentiment_y\"].fillna(4, inplace=True)\n",
    "\n",
    "true_pred[[\"aspect_x\", \"aspect_y\"]] = true_pred[[\"aspect_x\", \"aspect_y\"]].applymap(\n",
    "    lambda x: {v: k for k, v in asp_mapper.items()}[x]\n",
    ")\n",
    "true_pred[[\"sentiment_x\", \"sentiment_y\"]] = true_pred[[\"sentiment_x\", \"sentiment_y\"]].applymap(\n",
    "    lambda x: {v: k for k, v in sent_mapper.items()}[x]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb0755c-5151-4519-a611-698b7ec0d5e9",
   "metadata": {},
   "source": [
    "С аккураси немножко сложно, я помню статью с прошлого года, поэтому у меня их целых 4 варианта. Разница в том, считаем мы наны или нет. Если оба нан, то проблем нет, они в аккураси не учитываются, а если один из? Есть 4 варианта - разрешаем левому, правому, обоим, ни одному. Но попробуем побить все 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d8f71c7-36bb-43c1-b92f-660d861a205e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>pred</td>\n",
       "      <td>naïve</td>\n",
       "      <td>0.577543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>true</td>\n",
       "      <td>naïve</td>\n",
       "      <td>0.577543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>common</td>\n",
       "      <td>naïve</td>\n",
       "      <td>0.577543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>excluding</td>\n",
       "      <td>naïve</td>\n",
       "      <td>0.577543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aspect</td>\n",
       "      <td>pred</td>\n",
       "      <td>naïve</td>\n",
       "      <td>0.783345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aspect</td>\n",
       "      <td>true</td>\n",
       "      <td>naïve</td>\n",
       "      <td>0.244547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aspect</td>\n",
       "      <td>common</td>\n",
       "      <td>naïve</td>\n",
       "      <td>0.947099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aspect</td>\n",
       "      <td>excluding</td>\n",
       "      <td>naïve</td>\n",
       "      <td>0.232023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label     method  model  accuracy\n",
       "0  sentiment       pred  naïve  0.577543\n",
       "1  sentiment       true  naïve  0.577543\n",
       "2  sentiment     common  naïve  0.577543\n",
       "3  sentiment  excluding  naïve  0.577543\n",
       "4     aspect       pred  naïve  0.783345\n",
       "5     aspect       true  naïve  0.244547\n",
       "6     aspect     common  naïve  0.947099\n",
       "7     aspect  excluding  naïve  0.232023"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inference import custom_accuracy, get_full_sentiment\n",
    "\n",
    "answers = pd.DataFrame(columns=[\"label\", \"method\", \"model\", \"accuracy\"])\n",
    "for label in [\"sentiment\", \"aspect\"]:\n",
    "    for how in [\"pred\", \"true\", \"common\", \"excluding\"]:\n",
    "        answers.loc[answers.shape[0]] = {\n",
    "            \"method\": how, \"label\": label, \"model\": \"naïve\",\n",
    "            \"accuracy\": custom_accuracy(\n",
    "                true_pred[f\"{label}_x\"], true_pred[f\"{label}_y\"], how=how\n",
    "            ).item()\n",
    "        }\n",
    "        \n",
    "with open('valid_base_packed_cats.txt', 'w') as f:\n",
    "    for idx, c, s in get_full_sentiment(true_pred, \"aspect_x\", \"sentiment_x\"):\n",
    "        print(idx, c, s, sep=\"\\t\", file=f)\n",
    "        \n",
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d00864a-e958-4cf2-b217-b6a809b265b9",
   "metadata": {},
   "source": [
    "Если анализировать это дело, то выйдет вот что:\n",
    "1. Аспекты. Если игнорировать наны полностью, то всё вообще прекрасно, почти всегда попадаем. Но судя по `excluding` очень часто выходимм за рамки, слишком много лишнего\n",
    "2. Сентимент. Тут всё ещё хуже по обоим направлением, но в целом выводы все те же"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b1a82b-32fc-4eef-b46a-37edc5d4587c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Мета информацию про сами токены и позицию сохраним, она пригодится в дальнейшем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a986ea-3ad1-429a-9870-308c58893a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    true_pred[[\"text_id\", \"token\", \"begin\", \"end\"]] \\\n",
    "    .sort_values(\"text_id\") \\\n",
    "    .to_csv(\"valid_meta.csv\", index=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2eb2d1-beab-4a60-a12f-ea221728b5b4",
   "metadata": {},
   "source": [
    "И заодно можем посчитать, как это будет работать с исходным инференсом. Я сразу скажу, что я его не особо разбирал, там много строчек, может быть так действительно правильно, но меня интересовало сделать разметку на уровне токенов. Понятно, что для символов оно будет в целом так же, но тогда возникнут сложности с частью 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4179d6c2-1b01-4420-b2f3-41dc41683252",
   "metadata": {},
   "source": [
    "Если не собирвать аспекты, а оставить их по токенам, то будет грустно. В принципе мы увидим то же самое, что я сказал выше, только не уверен, насколько там уместно называть это пресижном и реколлом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "936e39ef-9ef6-4e1d-8289-893f4dd99431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full match precision</th>\n",
       "      <td>0.17209398186314923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full match recall</th>\n",
       "      <td>0.7142857142857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial match ratio in pred</th>\n",
       "      <td>0.2384583676834295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full category accuracy</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial category accuracy</th>\n",
       "      <td>0.17209398186314923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patial sentiment accuracy</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full sentiment accuracy</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall sentiment accuracy</th>\n",
       "      <td>0.9464788732394366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            None\n",
       "Full match precision         0.17209398186314923\n",
       "Full match recall             0.7142857142857143\n",
       "Partial match ratio in pred   0.2384583676834295\n",
       "Full category accuracy                       0.0\n",
       "Partial category accuracy    0.17209398186314923\n",
       "Patial sentiment accuracy                    0.0\n",
       "Full sentiment accuracy                      0.0\n",
       "Overall sentiment accuracy    0.9464788732394366"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inference import reference_check\n",
    "\n",
    "reference_check(\n",
    "    \"valid_aspects.txt\", \"valid_base_aspects.txt\",\n",
    "    \"valid_cats.txt\", \"valid_base_packed_cats.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0940093-206d-4159-aa03-e3e8d43f8345",
   "metadata": {},
   "source": [
    "А если собрать, то уже куда ни шло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bb091ad-9746-4109-84dc-e5cd888c0a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a96b4a23de94b24b8f79b353a1e48e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from inference import pack\n",
    "\n",
    "pack(\n",
    "    true_pred, \"aspect_x\", \"sentiment_x\",\n",
    "    'valid_base_packed_aspects.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d0b4d00-bb81-4efe-8a26-e32ebb4d80f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_packed</th>\n",
       "      <th>true_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full match precision</th>\n",
       "      <td>0.1480654761904762</td>\n",
       "      <td>0.4146224146224146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full match recall</th>\n",
       "      <td>0.34046193327630453</td>\n",
       "      <td>0.737382378100941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial match ratio in pred</th>\n",
       "      <td>0.33742559523809523</td>\n",
       "      <td>0.5108225108225108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full category accuracy</th>\n",
       "      <td>0.1402529761904762</td>\n",
       "      <td>0.4078884078884079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial category accuracy</th>\n",
       "      <td>0.2734375</td>\n",
       "      <td>0.5036075036075036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patial sentiment accuracy</th>\n",
       "      <td>0.6483300589390962</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full sentiment accuracy</th>\n",
       "      <td>0.6809045226130653</td>\n",
       "      <td>0.665893271461717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall sentiment accuracy</th>\n",
       "      <td>0.9464788732394366</td>\n",
       "      <td>0.4056338028169014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     base_packed           true_base\n",
       "Full match precision          0.1480654761904762  0.4146224146224146\n",
       "Full match recall            0.34046193327630453   0.737382378100941\n",
       "Partial match ratio in pred  0.33742559523809523  0.5108225108225108\n",
       "Full category accuracy        0.1402529761904762  0.4078884078884079\n",
       "Partial category accuracy              0.2734375  0.5036075036075036\n",
       "Patial sentiment accuracy     0.6483300589390962               0.605\n",
       "Full sentiment accuracy       0.6809045226130653   0.665893271461717\n",
       "Overall sentiment accuracy    0.9464788732394366  0.4056338028169014"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.concat([\n",
    "    reference_check(\n",
    "        \"valid_aspects.txt\", f\"valid_{model}_aspects.txt\",\n",
    "        \"valid_cats.txt\", f\"valid_{model}_cats.txt\", model=model\n",
    "    )\n",
    "    for model in [\"base_packed\", \"true_base\"]\n",
    "], axis=1)\n",
    "\n",
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e19fa-3518-481f-9743-652809d8191e",
   "metadata": {},
   "source": [
    "Получается, что уже достаточно лишь перейти к токенам, чтобы побить бейзлайн\n",
    "\n",
    "Так или иначе, будем стараться побить всё, что здесь есть. Очевидно, наивный подход не самый лучшмй вармант, разве что у меня реально много данных, но это не наш случай. Хотя если смотреть на общий сентимент, то вообще-то всё очень даже неплохо, хотя если честно, это как раз самое сложное, не понимаю, почему считается самым простым, потому что у меня нет правильных ответов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17eb262-f7f9-47c8-b223-f8fefa9682b3",
   "metadata": {},
   "source": [
    "### 2. BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8e31f-2529-4212-ad1b-38770f803484",
   "metadata": {},
   "source": [
    "Я взял вообще дефолтный берт и сразу решился дообучать его полностью, потому что могу это себе позволить. Все параметры стандартные, ничего хитрого\n",
    "https://wandb.ai/lerostre/assez?workspace=user-lerostre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f54bcd3a-ed65-4565-a0a1-633df4c00d06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlerostre\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7129d07a50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert import train, evaluate\n",
    "import wandb\n",
    "import torch\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "wandb.login()\n",
    "torch.manual_seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44fca59-ce90-4e38-b108-eed4f836fa56",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(\n",
    "    project=\"assez\", log_model='all', name=\"cat_only_bert\"\n",
    ")\n",
    "optimizer_params = {\n",
    "    \"optimizer\": torch.optim.Adam,\n",
    "    \"optimizer_kwargs\": dict(lr=5e-5),\n",
    "    \"scheduler\": get_cosine_schedule_with_warmup,\n",
    "    \"scheduler_kwargs\": dict(num_warmup_steps=20, num_training_steps=200),\n",
    "    \"weights\": [0, 0, 1]\n",
    "}\n",
    "training_arguments = {\n",
    "    \"max_epochs\": 50,\n",
    "    \"accelerator\": \"gpu\",\n",
    "    \"log_every_n_steps\": 1,\n",
    "    \"logger\": wandb_logger\n",
    "}\n",
    "\n",
    "train(\n",
    "    optimizer_params, training_arguments,\n",
    "    train_loader, valid_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76445f3a-a68c-4d8a-90a1-4f6bbd315ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20231229_052415-02k2qw60</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lerostre/assez/runs/02k2qw60' target=\"_blank\">cat_bert</a></strong> to <a href='https://wandb.ai/lerostre/assez' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lerostre/assez' target=\"_blank\">https://wandb.ai/lerostre/assez</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lerostre/assez/runs/02k2qw60' target=\"_blank\">https://wandb.ai/lerostre/assez/runs/02k2qw60</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-z10m03iu:best, 2031.39MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:3.5\n"
     ]
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(project=\"assez\", name=\"cat_bert\")\n",
    "# artifact = wandb_logger.use_artifact(\"lerostre/assez/model-1qlz2ava:best\")\n",
    "artifact = wandb_logger.use_artifact(\"lerostre/assez/model-z10m03iu:best\")\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fe2b41-7286-4891-9a47-630a7ad37a09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_res = evaluate(\"artifacts/model-z10m03iu:v49/model.ckpt\", valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3153658d-70fd-4ffb-a596-5e8a27e404e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c95e7cca68e4b52bc9b7b459444a7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6d2010c9e74df5b8fa0f17feb78c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bert import *\n",
    "\n",
    "model = AspectBERT.load_from_checkpoint(\"artifacts/model-z10m03iu:v49/model.ckpt\").to(\"cpu\")\n",
    "res = [model.step(batch, idx, log=False) for idx, batch in enumerate(valid_loader)]\n",
    "aspects = [\"aspect_true\", \"aspect_pred\"]\n",
    "sentiments = [\"sentiment_true\", \"sentiment_pred\"]\n",
    "clfs = [\"clf_true\", \"clf_pred\"]\n",
    "bert_res = pd.DataFrame(columns=aspects+sentiments)\n",
    "clf_bert = pd.DataFrame(columns=clfs)\n",
    "\n",
    "for batch in res:\n",
    "    batch[\"clf_true\"] = batch[\"clf_true\"].reshape(-1, 5)\n",
    "    batch[\"clf_pred\"] = batch[\"clf_pred\"].reshape(-1, 5)\n",
    "    for row in tqdm(zip(*list(batch.values())[4:-2])):\n",
    "        bert_res.loc[bert_res.shape[0]] = row\n",
    "    for row in zip(*list(batch.values())[-2:]):\n",
    "        clf_bert.loc[clf_bert.shape[0]] = row\n",
    "\n",
    "bert_res[aspects+sentiments] = bert_res[aspects+sentiments].applymap(lambda x: x.item())\n",
    "bert_res[aspects] = bert_res[aspects].applymap(\n",
    "    lambda x: {v: k for k, v in asp_mapper.items()}[x]\n",
    ")\n",
    "bert_res[sentiments] = bert_res[sentiments].applymap(\n",
    "    lambda x: {v: k for k, v in sent_mapper.items()}[x]\n",
    ")\n",
    "clf_bert[clfs] = clf_bert[clfs].applymap(\n",
    "    lambda x: [y.item() for y in x]\n",
    ")\n",
    "clf_bert[clfs] = clf_bert[clfs].applymap(\n",
    "    lambda x: list(map({v: k for k, v in sent_mapper.items()}.get, x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "27095d64-dd2d-4a76-a279-3ed18f28ebd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maspect\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommon\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexcluding\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 6\u001b[0m         \u001b[43manswers\u001b[49m\u001b[38;5;241m.\u001b[39mloc[answers\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: how, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: label, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: custom_accuracy(\n\u001b[1;32m      9\u001b[0m                 bert_res[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_true\u001b[39m\u001b[38;5;124m\"\u001b[39m], bert_res[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     10\u001b[0m                 how\u001b[38;5;241m=\u001b[39mhow)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     11\u001b[0m         }\n\u001b[1;32m     13\u001b[0m answers\u001b[38;5;241m.\u001b[39mloc[answers\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39midxmax()]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'answers' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from inference import custom_accuracy\n",
    "\n",
    "for label in [\"sentiment\", \"aspect\"]:\n",
    "    for how in [\"pred\", \"true\", \"common\", \"excluding\"]:\n",
    "        answers.loc[answers.shape[0]] = {\n",
    "            \"method\": how, \"label\": label, \"model\": \"bert\",\n",
    "            \"accuracy\": custom_accuracy(\n",
    "                bert_res[f\"{label}_true\"], bert_res[f\"{label}_pred\"],\n",
    "                how=how).item()\n",
    "        }\n",
    "        \n",
    "answers.loc[answers.groupby([\"label\", \"method\"])[\"accuracy\"].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfd9928-eaa7-4cba-b6ef-dfe4a289886a",
   "metadata": {},
   "source": [
    "Ну почти, в одной метрике не обогнал, но в общем-то и непонятно, почему мне нужно её брать. Я бы скорее смотрел на `common` или `excluding`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f57a8b6-78ca-47bb-971a-3aeb1ce37be2",
   "metadata": {},
   "source": [
    "На самом деле результаты не сказать, чтобы впечатляющие. Понятно, что если дать сетке другие тексты, которых она при обучении не видела, будет скорее всего не очень, потому что я сильно переобучился под данные, ну это и так понятно. Строго говоря, других данных у меня нет, я использую только то, что дают и оно работет прекрасно. Теперь по метрикам\n",
    "1. Аспекты выделяются почти идеально, если опустить наны. Если их не опускать, то видно, что с границами порядок примерно в 6 из 10 случаев, что тем не менее сильно лучше, чем раньше\n",
    "2. Сентимент остался на самом деле на уровне, но с границами теперь всё в разы лучше, больше попаданий\n",
    "\n",
    "Ну и глянем, как это выглядит, на исходной функции и с собранными н-граммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5cc6ff9-f8c3-4dc8-a7a1-55b001bec576",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9e2bd29b7a4e979fb67d15dc7e0a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from inference import pack, get_full_sentiment\n",
    "\n",
    "valid_meta = pd.read_csv(\"bert_valid_meta.csv\")[[\"text_id\", \"token\", \"begin\", \"end\"]]\n",
    "columns = [\"text_id\", \"aspect_pred\", \"token\", \"begin\", \"end\", \"sentiment_pred\"]\n",
    "\n",
    "bert_pretty_res = pd.concat([valid_meta, bert_res], axis=1)[columns]\n",
    "bert_pretty_res = bert_pretty_res.dropna().reset_index(drop=True)\n",
    "bert_pretty_res[[\"text_id\", \"begin\", \"end\"]] = bert_pretty_res[[\"text_id\", \"begin\", \"end\"]].astype(int)\n",
    "\n",
    "with open('valid_bert_aspects.txt', 'w') as f:\n",
    "    for idx, l in bert_pretty_res.iterrows():\n",
    "        print(*l.values, sep=\"\\t\", file=f)\n",
    "        \n",
    "with open('valid_bert_packed_cats.txt', 'w') as f:\n",
    "    for idx, row in enumerate(clf_bert[\"clf_pred\"].values):\n",
    "        for cat, sent in zip(\n",
    "            ['Food', 'Interior', 'Price', 'Whole', 'Service'], row\n",
    "        ):\n",
    "            print(valid_ids[idx], cat, sent, sep=\"\\t\", file=f)\n",
    "        \n",
    "pack(\n",
    "    bert_pretty_res, \"aspect_pred\", \"sentiment_pred\",\n",
    "    \"valid_bert_packed_aspects.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d64a0c7-4216-46a5-adbc-5c21718cd4e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_packed</th>\n",
       "      <th>true_base</th>\n",
       "      <th>bert_packed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full match precision</th>\n",
       "      <td>0.1480654761904762</td>\n",
       "      <td>0.4146224146224146</td>\n",
       "      <td>0.6991071428571428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full match recall</th>\n",
       "      <td>0.34046193327630453</td>\n",
       "      <td>0.737382378100941</td>\n",
       "      <td>0.669803250641574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial match ratio in pred</th>\n",
       "      <td>0.33742559523809523</td>\n",
       "      <td>0.5108225108225108</td>\n",
       "      <td>0.8232142857142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full category accuracy</th>\n",
       "      <td>0.1402529761904762</td>\n",
       "      <td>0.4078884078884079</td>\n",
       "      <td>0.6741071428571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial category accuracy</th>\n",
       "      <td>0.2734375</td>\n",
       "      <td>0.5036075036075036</td>\n",
       "      <td>0.8160714285714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patial sentiment accuracy</th>\n",
       "      <td>0.6483300589390962</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.7338129496402878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full sentiment accuracy</th>\n",
       "      <td>0.6809045226130653</td>\n",
       "      <td>0.665893271461717</td>\n",
       "      <td>0.756066411238825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall sentiment accuracy</th>\n",
       "      <td>0.12394366197183099</td>\n",
       "      <td>0.5492957746478874</td>\n",
       "      <td>0.6253521126760564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     base_packed           true_base  \\\n",
       "Full match precision          0.1480654761904762  0.4146224146224146   \n",
       "Full match recall            0.34046193327630453   0.737382378100941   \n",
       "Partial match ratio in pred  0.33742559523809523  0.5108225108225108   \n",
       "Full category accuracy        0.1402529761904762  0.4078884078884079   \n",
       "Partial category accuracy              0.2734375  0.5036075036075036   \n",
       "Patial sentiment accuracy     0.6483300589390962               0.605   \n",
       "Full sentiment accuracy       0.6809045226130653   0.665893271461717   \n",
       "Overall sentiment accuracy   0.12394366197183099  0.5492957746478874   \n",
       "\n",
       "                                    bert_packed  \n",
       "Full match precision         0.6991071428571428  \n",
       "Full match recall             0.669803250641574  \n",
       "Partial match ratio in pred  0.8232142857142857  \n",
       "Full category accuracy       0.6741071428571429  \n",
       "Partial category accuracy    0.8160714285714286  \n",
       "Patial sentiment accuracy    0.7338129496402878  \n",
       "Full sentiment accuracy       0.756066411238825  \n",
       "Overall sentiment accuracy   0.6253521126760564  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inference import reference_check\n",
    "\n",
    "full_df = pd.concat([\n",
    "    reference_check(\n",
    "        \"dev_aspects.txt\", f\"valid_{model}_aspects.txt\",\n",
    "        \"dev_cats.txt\", f\"valid_{model}_cats.txt\", model=model\n",
    "    )\n",
    "    for model in [\"base_packed\", \"true_base\", \"bert_packed\"]\n",
    "], axis=1)\n",
    "\n",
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f0671",
   "metadata": {},
   "source": [
    "### 3. Inference\n",
    "\n",
    "Инференс сделать достаточно легко, если датафреймы отзывов и аспектов 1 в 1, как те, что были даны на трейне, иначе что-то сломается. Я вообще не удивлюсь, если даже несмотря на это что-то сломается всё равно, уж очень данные специфические, неудобно с ними работать. Ниже код собственно воспроизводит всё то же, что и выше в ноутбуке, можно проверить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92220375-d3c8-4024-a395-30a570278560",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1886604d6daf44498236df0402f98e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/71 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlerostre\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d367f7d4ea94048b13083fabf88b066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113298622270425, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20231229_132251-9zzum7gk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lerostre/assez/runs/9zzum7gk' target=\"_blank\">cat_bert</a></strong> to <a href='https://wandb.ai/lerostre/assez' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lerostre/assez' target=\"_blank\">https://wandb.ai/lerostre/assez</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lerostre/assez/runs/9zzum7gk' target=\"_blank\">https://wandb.ai/lerostre/assez/runs/9zzum7gk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-z10m03iu:best, 2031.39MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:3.6\n",
      "/home/user/conda/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "from inference import inference\n",
    "\n",
    "inference(\"valid_texts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96490be-25c9-4508-b3a9-c858a2b82d07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full match precision</th>\n",
       "      <td>0.07566638005159071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full match recall</th>\n",
       "      <td>0.07527801539777587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial match ratio in pred</th>\n",
       "      <td>0.2226999140154772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full category accuracy</th>\n",
       "      <td>0.018056749785038694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial category accuracy</th>\n",
       "      <td>0.10834049871023216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patial sentiment accuracy</th>\n",
       "      <td>0.5263157894736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full sentiment accuracy</th>\n",
       "      <td>0.5340909090909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall sentiment accuracy</th>\n",
       "      <td>0.1352112676056338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             None\n",
       "Full match precision          0.07566638005159071\n",
       "Full match recall             0.07527801539777587\n",
       "Partial match ratio in pred    0.2226999140154772\n",
       "Full category accuracy       0.018056749785038694\n",
       "Partial category accuracy     0.10834049871023216\n",
       "Patial sentiment accuracy      0.5263157894736842\n",
       "Full sentiment accuracy        0.5340909090909091\n",
       "Overall sentiment accuracy     0.1352112676056338"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inference import reference_check\n",
    "\n",
    "reference_check(\n",
    "    \"dev_aspects.txt\", \"test_bert_packed_aspects.txt\",\n",
    "    \"dev_cats.txt\", \"test_bert_cats.txt\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
